{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ner_practise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SGA-TeqKU8J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "669cfaac-3a0e-4927-ee84-5d42966a2ae5"
      },
      "source": [
        "#ner practise :\n",
        "import os \n",
        "import nltk\n",
        "import nltk.corpus\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk import ne_chunk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VffKAux7uMbS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8658dac5-f2ed-48a7-98b3-4e91cb523809"
      },
      "source": [
        "para=\"\"\" This is a small demonstration .pdf file - \n",
        " just for use in the Virtual Mechanics tutorials. More text. And more  text. And more text. And more text. And more text. \n",
        " And more text. And more text. And more text. And more text. And more  text. And more text. Boring, zzzzz. And more text. And more text. And  more text. And more text. And more text. And more text. And more text.  And more text. And more text. \n",
        " And more text. And more text. And more text. And more text. And more  text. And more text. And more text. Even more. Continued on page 2 ...\"\"\"\n",
        "type(para)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJii0jI4uYyQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c1402de9-c50c-4469-b2b7-6967e9147e96"
      },
      "source": [
        "para_tokens=word_tokenize(para)\n",
        "print(para_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'is', 'a', 'small', 'demonstration', '.pdf', 'file', '-', 'just', 'for', 'use', 'in', 'the', 'Virtual', 'Mechanics', 'tutorials', '.', 'More', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'Boring', ',', 'zzzzz', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'And', 'more', 'text', '.', 'Even', 'more', '.', 'Continued', 'on', 'page', '2', '...']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB3-4b-oulrZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "373b4edf-1615-4e13-fe60-3465bc09522c"
      },
      "source": [
        "para_sent=sent_tokenize(para)\n",
        "para_sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' This is a small demonstration .pdf file - \\n just for use in the Virtual Mechanics tutorials.',\n",
              " 'More text.',\n",
              " 'And more  text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more  text.',\n",
              " 'And more text.',\n",
              " 'Boring, zzzzz.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And  more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'And more  text.',\n",
              " 'And more text.',\n",
              " 'And more text.',\n",
              " 'Even more.',\n",
              " 'Continued on page 2 ...']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku9EdGeOvkPK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a3f4dbb8-97ab-46b0-8d3c-4813ff076f65"
      },
      "source": [
        "para_tag=nltk.pos_tag(para_tokens)\n",
        "print(para_tag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('small', 'JJ'), ('demonstration', 'NN'), ('.pdf', 'NNP'), ('file', 'NN'), ('-', ':'), ('just', 'RB'), ('for', 'IN'), ('use', 'NN'), ('in', 'IN'), ('the', 'DT'), ('Virtual', 'NNP'), ('Mechanics', 'NNP'), ('tutorials', 'NNS'), ('.', '.'), ('More', 'JJR'), ('text', 'JJ'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('Boring', 'NNP'), (',', ','), ('zzzzz', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('And', 'CC'), ('more', 'JJR'), ('text', 'NN'), ('.', '.'), ('Even', 'RB'), ('more', 'RBR'), ('.', '.'), ('Continued', 'VBN'), ('on', 'IN'), ('page', 'NN'), ('2', 'CD'), ('...', ':')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQeWJIKCwDfb"
      },
      "source": [
        "#sen_tokens=word_tokenize(para)\n",
        "#for token in sen_tokens:\n",
        "#  print(nltk.pos_tag([token]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQH9U0mKwesc"
      },
      "source": [
        "para_ner=ne_chunk(para_tag)\n",
        "print(para_ner)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmGiUujY0vTi"
      },
      "source": [
        "nltk.download('Users')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfQKDHF3xLRm"
      },
      "source": [
        "file = open('sample.txt')\n",
        "text = file.read()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QccqKoCz29AK"
      },
      "source": [
        "text_tokens=word_tokenize(text)\n",
        "text_tag=nltk.pos_tag(text_tokens)\n",
        "text_ner=ne_chunk(text_tag)\n",
        "print(text_ner)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp0vnvxb3qSU"
      },
      "source": [
        "pattern = 'NP: {<DT>?<JJ>*<NN>}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cyVc_FQ5y0T"
      },
      "source": [
        "cp = nltk.RegexpParser(pattern)\n",
        "cr = cp.parse(text_ner)\n",
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xe_liLi8kw5"
      },
      "source": [
        "text_ner== cr\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}